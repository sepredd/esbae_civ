{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ceac7-b6d0-48c4-96b5-f08fdb21e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix, classification_report\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4edb8a3-d1ee-4cb4-943a-a819fdc66862",
   "metadata": {},
   "source": [
    "### 1 Load and prepare CEO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2305da-1174-4265-b3e0-5577f7103b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "ceo = pd.read_csv('ceo-RCI_ERP_AD_COLLECTION_FINAL-sample-data-2022-09-28.csv', delimiter=',')\n",
    "print(ceo.columns)\n",
    "\n",
    "#print(len(ceo))\n",
    "#ceo = ceo[ceo['OCS_2000'] == 'Terres forestieres']\n",
    "#print(len(ceo))\n",
    "\n",
    "# subset columns\n",
    "ceo = ceo[['plotid', 'lon', 'lat', 'CHG_2000_2015']]\n",
    "\n",
    "# add CNC column for classification\n",
    "ceo['cnc'] = ceo['CHG_2000_2015'].apply(lambda x: 0 if x == 'Stable' else 1)\n",
    "ceo.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b5964-e1b9-4b15-83c8-d3e350128ef9",
   "metadata": {},
   "source": [
    "### 2 Load and Prepare TS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c01fd-a56a-4df6-8f04-eb37f7657c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#ts = pd.read_pickle('results_Landsat_ndfi_1995-01-01_2000-01-01_2015-12-31_0.25.pickle')\n",
    "ts = pd.read_json('ts.json')\n",
    "# see all columns\n",
    "ts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d32190-2ca7-4f26-8502-5e34542d0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn nan to 0\n",
    "ts['gfc_lossyear'] = np.nan_to_num(ts['gfc_lossyear'])\n",
    "# create a binary loss\n",
    "ts['gfc_loss_binary'] = ts['gfc_lossyear'].apply(lambda x: 0 if x == 0 or x > 15 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff0fb7-e11e-4701-b885-d182d58a9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary deforestation\n",
    "ts['tmf_def_binary'] = ts['tmf_defyear'].apply(lambda x: 0 if x > 1999 and x < 2016 else 1)\n",
    "\n",
    "# create a binary degradation\n",
    "ts['tmf_deg_binary'] = ts['tmf_degyear'].apply(lambda x: 0 if x > 1999 and x < 2016 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058deb2e-2fd4-4ed1-a4f1-f583798d47d8",
   "metadata": {},
   "source": [
    "### 2.1 Select columns for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1503bf-eda5-4eae-bfa1-59786a64cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_classify = [\n",
    "    #'images', 'mon_images',\n",
    "    'gfc_tc00', \n",
    "    'gfc_loss_binary',\n",
    "    'tmf_2000', \n",
    "    'tmf_def_binary', 'tmf_deg_binary',\n",
    "    'bfast_magnitude',\n",
    "    'ccdc_magnitude', \n",
    "    'ltr_magnitude', 'ltr_dur', 'ltr_rate',\n",
    "    'cusum_confidence', 'cusum_magnitude', \n",
    "    'ts_mean', 'ts_sd', # we add this anyway in the next cell\n",
    "    'ts_min', 'ts_max',\n",
    "    'bs_slope_mean', 'bs_slope_sd', 'bs_slope_max', 'bs_slope_min'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71c9a2-b7e5-4347-b972-d587e3674b8c",
   "metadata": {},
   "source": [
    "### 2.2 Extract time-series statistics for each band and add to predicitive data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780867d-0029-4b1c-9b6a-27ecf0d0ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = list(ts['ts'][1].keys())\n",
    "print(' Bands available in dataset time-series: ')\n",
    "print(bands) \n",
    "for band in bands:\n",
    "    \n",
    "    # add mean and SD value of time-series for each band\n",
    "    ts[band + '_mean'] = ts['ts'].apply(lambda x: np.nanmean(np.array(x[band])))\n",
    "    ts[band + '_sd'] = ts['ts'].apply(lambda x: np.nanstd(np.array(x[band])))\n",
    "    \n",
    "    # append to classification bands\n",
    "    cols_to_classify.append(band + '_mean')\n",
    "    cols_to_classify.append(band + '_sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bc62b-b283-49c6-8f6b-19e30326a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5199ae-979e-4c72-8837-2d625b872c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Number of predictive features: ' + str(len(cols_to_classify)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37185585-2d0b-4499-92f4-7b8da6e6a919",
   "metadata": {},
   "source": [
    "### 2.3 Add a Kmeans column (because we can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe2dc6-1ba9-4b03-bbb1-ad09488a9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_cluster=50\n",
    "\n",
    "# run kmeans\n",
    "kmeans_model = KMeans(n_clusters=nr_of_cluster, random_state=42).fit(ts[cols_to_classify])\n",
    "ts['kmeans'] = kmeans_model.predict(ts[cols_to_classify])\n",
    "\n",
    "cols_to_classify.append('kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f2d440-bc51-41ed-a86a-8a3262f60e54",
   "metadata": {},
   "source": [
    "### 3 Merge CEO and TS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b47380-e380-4c29-951c-0300b379d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.merge(ceo, ts[cols_to_classify + ['PLOTID']], how='inner', left_on='plotid', right_on='PLOTID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed52957-df62-4958-b308-24e87a809985",
   "metadata": {},
   "outputs": [],
   "source": [
    "h.plot_stats_per_class(df_class, 'CHG_2000_2015', cols_to_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a69f67-b3cb-4b41-ad51-26ed7c9b3ecf",
   "metadata": {},
   "source": [
    "### 4 Classification - Ensemble model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4035b2-601b-4cce-9d90-13b0f8f916f6",
   "metadata": {},
   "source": [
    "### 4.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9614822-d4f4-4fbb-8db4-2e583e3e8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_class[cols_to_classify], df_class['cnc'], test_size=0.2, random_state=42, stratify=df_class['cnc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654c198-ba6b-44de-81f5-bba3dbda3f56",
   "metadata": {},
   "source": [
    "### 4.2 RF classifcation with automated model optimization for avoiding false positives in the stable class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58296a63-a10a-4818-aeb9-535664ef8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, oob_score=True)\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [10], \n",
    "    'n_estimators' : [500],\n",
    "    #'max_depth': [3, 5, 15, 25],\n",
    "    'max_features': [10]\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "\n",
    "def grid_search_wrapper(refit_score='recall_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score, cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(X_train[cols_to_classify], y_train)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(X_test[cols_to_classify])\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search\n",
    "\n",
    "grid_search_clf = grid_search_wrapper(refit_score='precision_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97890049-1e4a-4b55-8dc3-c9130b0642f7",
   "metadata": {},
   "source": [
    "### 4.3 Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1132a-5a53-471d-9eee-2e5165ed0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['class'] = grid_search_clf.predict(X_train[cols_to_classify])\n",
    "X_test['class'] = grid_search_clf.predict(X_test[cols_to_classify])\n",
    "\n",
    "print('-----------------------------')\n",
    "print(' Stats on train:')\n",
    "print('-----------------------------')\n",
    "print('Accuracy on train: ' + str(accuracy_score(y_train, X_train['class'])))\n",
    "display(confusion_matrix(y_train, X_train['class']))\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('-----------------------------')\n",
    "print(' Stats on test:')\n",
    "print('-----------------------------')\n",
    "#print('Out of Bag Error RF: ' + str(grid_search_clf.oob_score_))\n",
    "print('Accuracy on test: ' + str(accuracy_score(y_test, X_test['class'], )))\n",
    "cm = confusion_matrix(y_test, X_test['class'])\n",
    "display(cm)\n",
    "\n",
    "print('')\n",
    "print('')\n",
    "print('-----------------------------')\n",
    "print(' Per class stats on test:')\n",
    "print('-----------------------------')\n",
    "print(classification_report(y_test, X_test['class'], target_names=['stable', 'change'], digits=4))\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=['stable', 'change'], columns=['stable', 'change'])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cb0d3-6673-4b11-bf58-33081fc4f321",
   "metadata": {},
   "source": [
    "### 4.4 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f4d10-21af-410f-8388-d8614fdceb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = grid_search_clf.best_estimator_\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "feature_names = [f\"{i}\" for i in X_train[cols_to_classify].columns]\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using RF\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61305af-3b68-4882-95c0-51ff58386b5d",
   "metadata": {},
   "source": [
    "### 4.4 get threshhold for not having any change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66128ffc-b770-460f-8ce0-1e79e9dd6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class[['prob_stable', 'prob_change']] = grid_search_clf.predict_proba(df_class[cols_to_classify][cols_to_classify])\n",
    "\n",
    "print('Maximum probability of stable for change points')\n",
    "thshld = df_class['prob_stable'][df_class['cnc'] == 1].max()\n",
    "thshld = np.percentile(df_class['prob_stable'][df_class['cnc'] == 1], 90)\n",
    "print(thshld)\n",
    "\n",
    "print('Number of points above thshld (considered stable)')\n",
    "abv_thshld = df_class[df_class['prob_stable'] > thshld]\n",
    "print(str(len(abv_thshld)) + ' out of ' + str(len(df_class)))\n",
    "\n",
    "print('Number of actual change points left in stable')\n",
    "len(abv_thshld[abv_thshld['cnc'] == 1])\n",
    "\n",
    "print(' Point Ids of interpreted change with a high probability of being stable')\n",
    "display(df_class[(df_class['cnc'] == 1) & (df_class['prob_stable'] > 0.5)].sort_values('prob_stable', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287bfe0b-05ad-42bf-93c4-5098dca69a83",
   "metadata": {},
   "source": [
    "### 5 Apply ensemble model to ALL points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58bde0-d5df-456e-8782-d9d7e152b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['cnc_class'] = grid_search_clf.predict(ts[cols_to_classify])\n",
    "ts[['prob_stable', 'prob_change']] = grid_search_clf.predict_proba(ts[cols_to_classify])\n",
    "\n",
    "print(' Number of points to visually recheck based on classification result (0.5 probability)')\n",
    "print(len(ts[ts['cnc_class'] == 1]))\n",
    "\n",
    "\n",
    "print(' Number of points to visually recheck based on adjusted probability')\n",
    "print(len(ts[ts['prob_stable'] < thshld]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c9151-b989-4fb1-898d-19e9f1057aea",
   "metadata": {},
   "source": [
    "### 6 Select most likely change points based on probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c695a23-0cfe-43ae-a3a3-282300b78343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points you can afford to analyse\n",
    "nr_of_points = 5000\n",
    "\n",
    "# select\n",
    "selection = ts[['PLOTID', 'prob_change']].sort_values('prob_change', ascending=False).head(nr_of_points)\n",
    "display(selection)\n",
    "print('Minimum change probablity included in selection: ' + str(selection['prob_change'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe223e-b874-4ab7-883d-a254d7be6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Number of points to visually recheck based on margin of classifier') \n",
    "ts[['PLOTID', 'prob_change']][(ts['prob_change'] > 0.45) & (ts['prob_change'] < 0.55)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b1651-865f-45ca-90a6-88f0d599d944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
